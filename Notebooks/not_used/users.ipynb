{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9b3f1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mMissing required @injectable annotation in: eb. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, PoissonRegressor\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = Path(\"Datasets/mockup_ver2/\")  # เปลี่ยนเป็นโฟลเดอร์ของคุณได้\n",
    "TX_CANDIDATES = BASE/\"transactions.csv\"\n",
    "USERS_PATH = BASE/\"users.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a6702",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = pd.read_csv(TX_CANDIDATES)\n",
    "tx[\"timestamp\"] = pd.to_datetime(tx[\"timestamp\"],format=\"%d/%m/%Y %H:%M\" )\n",
    "\n",
    "tx[\"order_date\"] = tx[\"timestamp\"].dt.date\n",
    "tx[\"order_hour\"] = tx[\"timestamp\"].dt.hour\n",
    "tx[\"dayofweek\"]  = tx[\"timestamp\"].dt.dayofweek  # Mon=0..Sun=6\n",
    "tx[\"is_weekend\"] = tx[\"dayofweek\"].isin([5,6]).astype(int)\n",
    "tx[\"month\"]      = tx[\"timestamp\"].dt.month\n",
    "\n",
    "tx[\"unit_price\"] = np.where(tx[\"qty\"]>0, tx[\"price\"]/tx[\"qty\"], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b0905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "txn = (\n",
    "    tx.groupby([\"user_id\",\"transaction_id\"], as_index=False)\n",
    "      .agg({\n",
    "          \"timestamp\":\"min\",\n",
    "          \"qty\":\"sum\",\n",
    "          \"price\":\"sum\",\n",
    "          \"unit_price\":\"mean\",\n",
    "          \"order_hour\":\"min\",\n",
    "          \"dayofweek\":\"min\",\n",
    "          \"is_weekend\":\"max\",\n",
    "          \"month\":\"min\",\n",
    "      })\n",
    "      .sort_values([\"user_id\",\"timestamp\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d3dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "txn[\"next_ts\"] = txn.groupby(\"user_id\")[\"timestamp\"].shift(-1)\n",
    "txn[\"days_to_next\"] = (txn[\"next_ts\"] - txn[\"timestamp\"]).dt.days\n",
    "txn[\"repeat_30d\"] = (txn[\"days_to_next\"].notna() & (txn[\"days_to_next\"] <= 30)).astype(int)\n",
    "\n",
    "X_rep = pd.get_dummies(\n",
    "    txn[[\"is_weekend\",\"month\",\"order_hour\",\"price\"]],\n",
    "    columns=[\"month\",\"order_hour\"], drop_first=True\n",
    ").fillna(0)\n",
    "y_rep = txn[\"repeat_30d\"]\n",
    "\n",
    "# กันเคสข้อมูลน้อยมาก\n",
    "if y_rep.nunique() == 1:\n",
    "    # ถ้าไม่มีความแปรผันเลย ให้ตั้งค่าเฉลี่ยเป็นสcore\n",
    "    p_avg = float(y_rep.mean())\n",
    "    txn[\"pred_repeat_prob\"] = p_avg\n",
    "else:\n",
    "    logit = LogisticRegression(max_iter=1000, random_state=SEED)\n",
    "    logit.fit(X_rep, y_rep)\n",
    "    txn[\"pred_repeat_prob\"] = logit.predict_proba(X_rep)[:,1]\n",
    "\n",
    "user_loyalty = txn.groupby(\"user_id\")[\"pred_repeat_prob\"].mean().rename(\"loyalty_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9077b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bsk = pd.get_dummies(\n",
    "    txn[[\"is_weekend\",\"month\",\"order_hour\"]],\n",
    "    columns=[\"month\",\"order_hour\"], drop_first=True\n",
    ").fillna(0)\n",
    "y_bsk = txn[\"qty\"].clip(lower=0)\n",
    "\n",
    "if len(txn) < 30 or y_bsk.nunique() <= 1:\n",
    "    # ข้อมูลน้อยหรือไม่มีความแปรผัน\n",
    "    pred_basket = np.repeat(y_bsk.mean(), len(txn))\n",
    "else:\n",
    "    poisson = PoissonRegressor(alpha=0.1, max_iter=500)\n",
    "    poisson.fit(X_bsk, y_bsk)\n",
    "    pred_basket = poisson.predict(X_bsk).clip(min=0)\n",
    "\n",
    "txn[\"pred_basket_qty\"] = pred_basket\n",
    "user_basket = txn.groupby(\"user_id\")[\"pred_basket_qty\"].mean().rename(\"expected_basket_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae6554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elasticity_per_user(g):\n",
    "    g = g.dropna(subset=[\"qty\",\"unit_price\"]).copy()\n",
    "    g = g[(g[\"qty\"]>0) & (g[\"unit_price\"]>0)]\n",
    "    if g[\"unit_price\"].nunique() < 3 or len(g) < 5:\n",
    "        return np.nan\n",
    "    X = np.log(g[[\"unit_price\"]].values)\n",
    "    y = np.log(g[\"qty\"].values)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X, y)\n",
    "    return float(lr.coef_[0])\n",
    "\n",
    "user_elast = txn.groupby(\"user_id\").apply(elasticity_per_user).rename(\"price_elasticity\")\n",
    "\n",
    "def global_elast_fn(df):\n",
    "    d = df.dropna(subset=[\"qty\",\"unit_price\"])\n",
    "    d = d[(d[\"qty\"]>0) & (d[\"unit_price\"]>0)]\n",
    "    if d[\"unit_price\"].nunique() < 3 or len(d) < 20:\n",
    "        return -1.8\n",
    "    X = np.log(d[[\"unit_price\"]].values)\n",
    "    y = np.log(d[\"qty\"].values)\n",
    "    lr = LinearRegression().fit(X, y)\n",
    "    return float(lr.coef_[0])\n",
    "global_elast = global_elast_fn(txn)\n",
    "user_elast = user_elast.fillna(global_elast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aaf2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_features = pd.concat([user_loyalty, user_basket, user_elast], axis=1).reset_index()\n",
    "users_features[\"loyalty_score\"] = users_features[\"loyalty_score\"].clip(0,1)\n",
    "users_features[\"expected_basket_items\"] = users_features[\"expected_basket_items\"].clip(0,50)\n",
    "users_features[\"price_elasticity\"] = users_features[\"price_elasticity\"].clip(-5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6fd8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_cols = [\"loyalty_score\",\"expected_basket_items\",\"price_elasticity\"]\n",
    "Z = users_features[cluster_cols].fillna(users_features[cluster_cols].median())\n",
    "scaler = StandardScaler()\n",
    "Zs = scaler.fit_transform(Z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56234a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== ใช้ users_features แทน tx ====\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "FEATURE_COLS = [\"loyalty_score\", \"expected_basket_items\", \"price_elasticity\"]\n",
    "K_RANGE = range(2, 11)\n",
    "SEED = 42\n",
    "\n",
    "# 1) ถ้ายังไม่มี users_features (เพิ่งคำนวณเสร็จด้านบน), ข้ามส่วนนี้\n",
    "#    แต่ถ้าเริ่มจากไฟล์ ให้โหลด:\n",
    "# users_features = pd.read_csv(BASE/\"users_features_model.csv\")\n",
    "\n",
    "# 2) เลือกฟีเจอร์จาก users_features (ไม่ใช่ tx)\n",
    "X = users_features[FEATURE_COLS].copy()\n",
    "\n",
    "# 3) กัน inf/NaN แล้วสเกล\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "X = X.fillna(X.median(numeric_only=True))\n",
    "\n",
    "scaler_k = StandardScaler()\n",
    "Xs = scaler_k.fit_transform(X)\n",
    "\n",
    "# 4) ลูปหา K ที่ดี\n",
    "rows = []\n",
    "for k in K_RANGE:\n",
    "    km = KMeans(n_clusters=k, n_init=20, random_state=SEED)\n",
    "    labels = km.fit_predict(Xs)\n",
    "\n",
    "    sse = float(km.inertia_)\n",
    "    sil = silhouette_score(Xs, labels) if k > 1 else np.nan\n",
    "    ch  = calinski_harabasz_score(Xs, labels)\n",
    "    db  = davies_bouldin_score(Xs, labels)\n",
    "\n",
    "    rows.append({\"K\": k, \"SSE\": sse, \"Silhouette\": sil, \"CalinskiHarabasz\": ch, \"DaviesBouldin\": db})\n",
    "\n",
    "metrics = pd.DataFrame(rows)\n",
    "\n",
    "# 5) แนะนำ K\n",
    "best_sil_k = int(metrics.loc[metrics[\"Silhouette\"].idxmax(), \"K\"])\n",
    "metrics[\"rank_sil\"] = metrics[\"Silhouette\"].rank(ascending=False, method=\"min\")\n",
    "metrics[\"rank_ch\"]  = metrics[\"CalinskiHarabasz\"].rank(ascending=False, method=\"min\")\n",
    "metrics[\"rank_db\"]  = metrics[\"DaviesBouldin\"].rank(ascending=True,  method=\"min\")\n",
    "metrics[\"rank_total\"] = (metrics[\"rank_sil\"]*0.5 + metrics[\"rank_ch\"]*0.3 + metrics[\"rank_db\"]*0.2)\n",
    "best_combo_k = int(metrics.sort_values(\"rank_total\").iloc[0][\"K\"])\n",
    "\n",
    "print(\"=== Metrics by K ===\")\n",
    "print(metrics[[\"K\",\"SSE\",\"Silhouette\",\"CalinskiHarabasz\",\"DaviesBouldin\",\"rank_total\"]])\n",
    "print(\"\\nSuggestion:\")\n",
    "print(f\"- By Silhouette peak => K = {best_sil_k}\")\n",
    "print(f\"- By combined ranks  => K = {best_combo_k}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aad681",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5  # ปรับได้\n",
    "kmeans = KMeans(n_clusters=k, n_init=20, random_state=SEED)\n",
    "users_features[\"segment\"] = kmeans.fit_predict(Zs)\n",
    "\n",
    "centers = pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_), columns=cluster_cols)\n",
    "desc = []\n",
    "for i, r in centers.iterrows():\n",
    "    desc.append(f\"S{i}: loyalty~{r['loyalty_score']:.2f}, basket~{r['expected_basket_items']:.2f}, elast~{r['price_elasticity']:.2f}\")\n",
    "seg_map = {i: d for i, d in enumerate(desc)}\n",
    "users_features[\"segment_desc\"] = users_features[\"segment\"].map(seg_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439f1d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Build & Save ONE FILE: user_id + metrics + segment ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "BASE = Path(\"Datasets/mockup_ver2/\")\n",
    "BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) เอา users_features: ใช้จากตัวแปรถ้ามี, ไม่งั้นโหลดจากไฟล์ที่เคยเซฟ\n",
    "candidates = [\n",
    "    BASE / \"users_features_model_k5.csv\",\n",
    "    BASE / \"users_features_model.csv\",\n",
    "    BASE / \"users_features_with_segments.csv\",  # เผื่อเคยสร้างแล้ว\n",
    "]\n",
    "if 'users_features' in globals():\n",
    "    df = users_features.copy()\n",
    "else:\n",
    "    df = None\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            df = pd.read_csv(p)\n",
    "            break\n",
    "    if df is None:\n",
    "        raise FileNotFoundError(\n",
    "            \"ไม่พบตัวแปร users_features และไม่มีไฟล์ users_features_model*.csv ในโฟลเดอร์ \"\n",
    "            f\"{BASE}. โปรดรันขั้นตอนคำนวณ users_features ก่อนครับ.\"\n",
    "        )\n",
    "\n",
    "# 2) ตรวจว่ามีคอลัมน์ metric หลักครบ\n",
    "REQUIRED_METRICS = {\"user_id\",\"loyalty_score\",\"expected_basket_items\",\"price_elasticity\"}\n",
    "missing = REQUIRED_METRICS - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"ขาดคอลัมน์จำเป็นใน users_features: {missing}\")\n",
    "\n",
    "# 3) ถ้ายังไม่มี segment → ทำคลัสเตอร์ (k=5) ให้เลย\n",
    "if \"segment\" not in df.columns:\n",
    "    cluster_cols = [\"loyalty_score\",\"expected_basket_items\",\"price_elasticity\"]\n",
    "    Z = df[cluster_cols].copy()\n",
    "    Z = Z.replace([np.inf, -np.inf], np.nan).fillna(Z.median(numeric_only=True))\n",
    "\n",
    "    scaler = StandardScaler().fit(Z)\n",
    "    Zs = scaler.transform(Z)\n",
    "\n",
    "    SEED = 42\n",
    "    k = 5\n",
    "    kmeans = KMeans(n_clusters=k, n_init=20, random_state=SEED).fit(Zs)\n",
    "    df[\"segment\"] = kmeans.labels_\n",
    "\n",
    "    # สร้างคำอธิบายคลัสเตอร์ (segment_desc) จาก centroid (หน่วยเดิม)\n",
    "    centers = pd.DataFrame(\n",
    "        scaler.inverse_transform(kmeans.cluster_centers_),\n",
    "        columns=cluster_cols\n",
    "    ).round(3)\n",
    "    centers.index.name = \"segment\"\n",
    "    centers = centers.reset_index()\n",
    "\n",
    "    desc = []\n",
    "    for _, r in centers.iterrows():\n",
    "        desc.append(\n",
    "            f\"S{int(r['segment'])}: loyalty~{r['loyalty_score']:.2f}, \"\n",
    "            f\"basket~{r['expected_basket_items']:.2f}, \"\n",
    "            f\"elast~{r['price_elasticity']:.2f}\"\n",
    "        )\n",
    "    seg_map = {int(r[\"segment\"]): d for r, d in zip(centers.to_dict(\"records\"), desc)}\n",
    "    df[\"segment_desc\"] = df[\"segment\"].map(seg_map)\n",
    "\n",
    "# 4) เลือกคอลัมน์ที่ต้องการเป็น “ไฟล์เดียว”\n",
    "cols = [\"user_id\",\"loyalty_score\",\"expected_basket_items\",\"price_elasticity\",\"segment\"]\n",
    "if \"segment_desc\" in df.columns:\n",
    "    cols.append(\"segment_desc\")\n",
    "\n",
    "out_df = df[cols].copy()\n",
    "out_df[\"loyalty_score\"] = out_df[\"loyalty_score\"].round(3)\n",
    "out_df[\"expected_basket_items\"] = out_df[\"expected_basket_items\"].round(2)\n",
    "out_df[\"price_elasticity\"] = out_df[\"price_elasticity\"].round(2)\n",
    "\n",
    "# 5) เซฟไฟล์เดียว\n",
    "OUT_PATH = BASE / \"users_features_with_segments.csv\"\n",
    "out_df.to_csv(OUT_PATH, index=False)\n",
    "print(f\"Saved -> {OUT_PATH}\")\n",
    "\n",
    "# (ทางเลือก) ดูตัวอย่าง 5 แถว\n",
    "display(out_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
