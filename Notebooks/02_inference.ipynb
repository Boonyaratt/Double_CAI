{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02_inference â€” Promotion Recommendation Scoring\n",
        "\n",
        "This notebook loads saved artifacts and scores new baskets using the current `promotions.csv` as candidate source. It follows the same feature order and preprocessors saved during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Artifacts loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load artifacts & config\n",
        "import os, json, joblib, yaml\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "with open('../config/training_config.yaml', 'r', encoding='utf-8') as f:\n",
        "    CFG = yaml.safe_load(f)\n",
        "\n",
        "# Fix relative paths in config (since we're running from notebooks/)\n",
        "PROJECT_ROOT = Path('../').resolve()\n",
        "for key in CFG['paths']:\n",
        "    path_value = CFG['paths'][key]\n",
        "    if not Path(path_value).is_absolute():\n",
        "        CFG['paths'][key] = str(PROJECT_ROOT / path_value)\n",
        "\n",
        "ptype_model = joblib.load(os.path.join(CFG['paths']['models_dir'], 'ptype_model.pkl'))\n",
        "ranker_model = joblib.load(os.path.join(CFG['paths']['models_dir'], 'ranker_model.pkl'))\n",
        "scaler_need = joblib.load(os.path.join(CFG['paths']['preprocessors_dir'], 'scaler_need.pkl'))\n",
        "pca_need = joblib.load(os.path.join(CFG['paths']['preprocessors_dir'], 'pca_need.pkl'))\n",
        "kmeans_need = joblib.load(os.path.join(CFG['paths']['preprocessors_dir'], 'kmeans_need.pkl'))\n",
        "\n",
        "with open(os.path.join(CFG['paths']['metadata_dir'], 'ptype_classes.json'),'r',encoding='utf-8') as f:\n",
        "    ptype_classes = json.load(f)\n",
        "with open(os.path.join(CFG['paths']['metadata_dir'], 'ptype_featcols.json'),'r',encoding='utf-8') as f:\n",
        "    ptype_featcols = json.load(f)\n",
        "with open(os.path.join(CFG['paths']['metadata_dir'], 'ranker_featcols.json'),'r',encoding='utf-8') as f:\n",
        "    ranker_featcols = json.load(f)\n",
        "\n",
        "print('Artifacts loaded.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_need' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m need_states\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Predict need-states\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m need_states \u001b[38;5;241m=\u001b[39m predict_need_states(\u001b[43mX_need\u001b[49m, artifacts)\n\u001b[0;32m     17\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneed_state\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m need_states\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted need-states for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(need_states)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m transactions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'X_need' is not defined"
          ]
        }
      ],
      "source": [
        "# Predict need-states for users\n",
        "def predict_need_states(X_need, artifacts):\n",
        "    \"\"\"Predict need-states using saved preprocessors\"\"\"\n",
        "    # Scale features\n",
        "    X_scaled = artifacts['scaler_need'].transform(X_need)\n",
        "    \n",
        "    # Apply PCA\n",
        "    X_pca = artifacts['pca_need'].transform(X_scaled)\n",
        "    \n",
        "    # Predict clusters\n",
        "    need_states = artifacts['kmeans_need'].predict(X_pca)\n",
        "    \n",
        "    return need_states\n",
        "\n",
        "# Predict need-states\n",
        "need_states = predict_need_states(X_need, artifacts)\n",
        "df['need_state'] = need_states\n",
        "\n",
        "print(f\"Predicted need-states for {len(need_states)} transactions\")\n",
        "print(f\"Need-state distribution: {np.bincount(need_states)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helpers (align with training)\n",
        "from datetime import datetime\n",
        "\n",
        "def add_time_features(df: pd.DataFrame, time_col: str) -> pd.DataFrame:\n",
        "    ts = pd.to_datetime(df[time_col], errors='coerce')\n",
        "    df['hour'] = ts.dt.hour\n",
        "    df['dayofweek'] = ts.dt.dayofweek\n",
        "    df['month'] = ts.dt.month\n",
        "    df['is_weekend'] = ((df['dayofweek'] >= 5).astype(int))\n",
        "    return df\n",
        "\n",
        "\n",
        "def transform_need_state(basket_df: pd.DataFrame, need_features: list, scaler, pca, kmeans):\n",
        "    X_scaled = scaler.transform(basket_df[need_features].fillna(0.0))\n",
        "    X_pca = pca.transform(X_scaled)\n",
        "    clusters = kmeans.predict(X_pca)\n",
        "    ns = pd.DataFrame(X_pca, index=basket_df.index, columns=[f'ns_pca_{i+1}' for i in range(X_pca.shape[1])])\n",
        "    ns['ns_cluster'] = clusters\n",
        "    return ns\n",
        "\n",
        "\n",
        "def compute_scope_match(basket_row: pd.Series, cand_df: pd.DataFrame) -> pd.Series:\n",
        "    prod_scope = CFG['column_map_promo'].get('product_scope')\n",
        "    basket_products = basket_row.get('basket_products', set())\n",
        "    if (prod_scope is None) or (prod_scope not in cand_df.columns) or len(basket_products) == 0:\n",
        "        return pd.Series([0.0]*len(cand_df), index=cand_df.index)\n",
        "    def score(val):\n",
        "        if pd.isna(val):\n",
        "            return 0.0\n",
        "        try:\n",
        "            scope_set = set(str(val).split(','))\n",
        "            overlap = scope_set.intersection(set(map(str, basket_products)))\n",
        "            return float(len(overlap)) / float(max(1, len(scope_set)))\n",
        "        except Exception:\n",
        "            return 0.0\n",
        "    return cand_df[prod_scope].apply(score)\n",
        "\n",
        "\n",
        "def recall_candidates(basket_row, promos_df, ptype_probs, ptype_classes, cfg):\n",
        "    order = np.argsort(ptype_probs)[::-1]\n",
        "    sel = [ptype_classes[i] for i in order if ptype_probs[i] >= cfg['recall']['relevance_threshold']][:cfg['recall']['topk_types']]\n",
        "    ptype_set = set(sel)\n",
        "    cand = promos_df.copy()\n",
        "    if cfg['filters'].get('respect_channel', False) and ('channel' in cand.columns):\n",
        "        if bool(basket_row[cfg['column_map_tx']['is_online']]):\n",
        "            cand = cand[cand['channel'].astype(str).str.lower().eq('online')]\n",
        "        else:\n",
        "            cand = cand[cand['channel'].astype(str).str.lower().eq('offline')]\n",
        "    if cfg['filters'].get('use_time_window', True):\n",
        "        sd = cfg['column_map_promo'].get('start_date')\n",
        "        ed = cfg['column_map_promo'].get('end_date')\n",
        "        ts = basket_row[cfg['column_map_tx']['timestamp']]\n",
        "        if (sd in cand.columns) and (ed in cand.columns):\n",
        "            cand = cand[(cand[sd] <= ts) & (ts <= cand[ed])]\n",
        "    if cfg['filters'].get('respect_store_scope', False) and ('store_scope' in cand.columns):\n",
        "        # best-effort simple store list filter\n",
        "        sid = str(basket_row[cfg['column_map_tx']['store_id']])\n",
        "        def ok(rec):\n",
        "            v = rec.get('store_scope')\n",
        "            if pd.isna(v):\n",
        "                return True\n",
        "            return sid in str(v).split(',')\n",
        "        cand = cand[cand.apply(ok, axis=1)]\n",
        "    cand = cand[cand[cfg['column_map_promo']['promo_type']].isin(ptype_set)]\n",
        "    amt = float(basket_row.get('amount_total', 0.0))\n",
        "    minsp = cfg['column_map_promo'].get('min_spend')\n",
        "    if minsp and (minsp in cand.columns):\n",
        "        cand = cand.assign(min_spend_gap=np.maximum(0.0, cand[minsp].fillna(0) - amt))\n",
        "    else:\n",
        "        cand = cand.assign(min_spend_gap=0.0)\n",
        "    cand = cand.assign(scope_match_score=compute_scope_match(basket_row, cand))\n",
        "    return cand.reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Debug: Check what promo_type one-hot features we need\n",
        "print(f\"Ranker expects these promo_type features: {[f for f in ranker_featcols if f.startswith('promo_type__')]}\")\n",
        "print(f\"\\nUnique promo types in candidates: {promos[CFG['column_map_promo']['promo_type']].unique()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prepared inference inputs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25812\\3898273582.py:55: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  promos[col] = pd.to_datetime(promos[col], errors='coerce')\n",
            "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_25812\\3898273582.py:55: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  promos[col] = pd.to_datetime(promos[col], errors='coerce')\n"
          ]
        }
      ],
      "source": [
        "# Inference: load inputs\n",
        "# Example expects your new baskets in data_tx schema (minimal columns). For demo, we reuse a small sample from data/tx_merge3.csv\n",
        "baskets = pd.read_csv(CFG['paths']['data_tx']).head(200)\n",
        "# Parse timestamp\n",
        "baskets[CFG['column_map_tx']['timestamp']] = pd.to_datetime(baskets[CFG['column_map_tx']['timestamp']], errors='coerce')\n",
        "\n",
        "# Aggregate to basket-level similar to training\n",
        "c = CFG['column_map_tx']\n",
        "if ('amount_total' not in baskets.columns) and (c.get('amount_total') not in baskets.columns):\n",
        "    baskets['__amount'] = baskets[c['price']] * baskets[c['qty']]\n",
        "else:\n",
        "    baskets['__amount'] = baskets.get(c.get('amount_total'), baskets.get('amount_total', np.nan))\n",
        "if ('qty_total' not in baskets.columns) and (c.get('qty_total') not in baskets.columns):\n",
        "    baskets['__qty'] = baskets[c['qty']]\n",
        "else:\n",
        "    baskets['__qty'] = baskets.get(c.get('qty_total'), baskets.get('qty_total', np.nan))\n",
        "\n",
        "agg = baskets.groupby(c['transaction_id'], as_index=False).agg({\n",
        "    c['user_id']: 'first',\n",
        "    c['store_id']: 'first',\n",
        "    c['timestamp']: 'first',\n",
        "    c['zone']: 'first',\n",
        "    c['province']: 'first',\n",
        "    c['profile']: 'first',\n",
        "    c['is_online']: 'first',\n",
        "    '__amount': 'sum',\n",
        "    '__qty': 'sum'\n",
        "}).rename(columns={'__amount':'amount_total','__qty':'qty_total'})\n",
        "\n",
        "# Basket products set\n",
        "prod_col = c.get('product_id', 'product_id')\n",
        "if prod_col in baskets.columns:\n",
        "    prod_by_tx = (baskets.groupby(c['transaction_id'])[prod_col]\n",
        "                  .apply(lambda s: set(s.astype(str)))\n",
        "                  .rename('basket_products'))\n",
        "    agg = agg.merge(prod_by_tx, left_on=c['transaction_id'], right_index=True, how='left')\n",
        "else:\n",
        "    agg['basket_products'] = [set()]*len(agg)\n",
        "\n",
        "# Time features\n",
        "agg = add_time_features(agg, c['timestamp'])\n",
        "\n",
        "# Need-state features\n",
        "need_features = ['amount_total','qty_total']\n",
        "for opt in ['expected_basket_items','loyalty_score','price_elasticity']:\n",
        "    if opt in agg.columns:\n",
        "        need_features.append(opt)\n",
        "ns_df = transform_need_state(agg, need_features, scaler_need, pca_need, kmeans_need)\n",
        "\n",
        "# Load promos snapshot\n",
        "promos = pd.read_csv(CFG['paths']['data_promos'])\n",
        "for dcol in ['start_date','end_date']:\n",
        "    col = CFG['column_map_promo'].get(dcol)\n",
        "    if col and col in promos.columns:\n",
        "        promos[col] = pd.to_datetime(promos[col], errors='coerce')\n",
        "\n",
        "print('Prepared inference inputs.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Debug: Check feature alignment\n",
        "print(f\"Expected ranker features ({len(ranker_featcols)}): {ranker_featcols[:5]}... {ranker_featcols[-5:]}\")\n",
        "print(f\"\\nActual rank_infer columns ({len(rank_infer.columns)}): {rank_infer.columns.tolist()[:5]}... {rank_infer.columns.tolist()[-5:]}\")\n",
        "print(f\"\\nMissing features: {set(ranker_featcols) - set(rank_infer.columns)}\")\n",
        "print(f\"Extra features: {set(rank_infer.columns) - set(ranker_featcols) - {'transaction_id', 'promo_id', 'promo_type', 'score'}}\")\n",
        "print(f\"\\nSample ranking scores: {rank_infer['score'].describe()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage-A scoring done.\n"
          ]
        }
      ],
      "source": [
        "# Stage-A scoring (ptype)\n",
        "# Build X_ptype in the same column order as training\n",
        "X_base_cols = [c for c in ptype_featcols if not c.startswith('ns_pca_') and c != 'ns_cluster']\n",
        "X_ptype_infer = pd.concat([agg.reindex(columns=[col for col in X_base_cols]), ns_df[[col for col in ptype_featcols if col in ns_df.columns]]], axis=1).fillna(0)\n",
        "\n",
        "ptype_proba = ptype_model.predict_proba(X_ptype_infer.values)\n",
        "\n",
        "# Keep mapping for fast access per row\n",
        "ptype_probs_by_type = []\n",
        "for i in range(len(agg)):\n",
        "    row = ptype_proba[i]\n",
        "    pmap = {ptype_classes[j]: float(row[j]) for j in range(len(ptype_classes))}\n",
        "    ptype_probs_by_type.append(pmap)\n",
        "\n",
        "agg['ptype_probs'] = list(ptype_proba)\n",
        "agg['ptype_probs_by_type'] = ptype_probs_by_type\n",
        "print('Stage-A scoring done.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Built ranking features and scored candidates.\n"
          ]
        }
      ],
      "source": [
        "# Candidate recall and ranking features build\n",
        "rank_rows = []\n",
        "ptype_col = CFG['column_map_promo']['promo_type']\n",
        "pid_col = CFG['column_map_promo']['promo_id']\n",
        "\n",
        "for idx, row in agg.iterrows():\n",
        "    probs = np.array(row['ptype_probs'])\n",
        "    cand = recall_candidates(row, promos, probs, ptype_classes, CFG)\n",
        "    ts = row[CFG['column_map_tx']['timestamp']]\n",
        "    sd = CFG['column_map_promo'].get('start_date')\n",
        "    ed = CFG['column_map_promo'].get('end_date')\n",
        "    for _, p in cand.iterrows():\n",
        "        feat = {\n",
        "            'transaction_id': row[CFG['column_map_tx']['transaction_id']],\n",
        "            'promo_id': p[pid_col],\n",
        "            'promo_type': p[ptype_col],\n",
        "            'ptype_prob': float(row['ptype_probs_by_type'].get(p[ptype_col], 0.0)),\n",
        "            'scope_match_score': float(p.get('scope_match_score', 0.0)),\n",
        "            'min_spend_gap': float(p.get('min_spend_gap', 0.0)),\n",
        "            'channel_match': int((bool(row[CFG['column_map_tx']['is_online']]) and str(p.get('channel','')).lower()=='online') or ((not bool(row[CFG['column_map_tx']['is_online']])) and str(p.get('channel','')).lower()=='offline')),\n",
        "            'within_window': int((sd in p.index and ed in p.index and pd.notna(p[sd]) and pd.notna(p[ed]) and (p[sd] <= ts) and (ts <= p[ed])))\n",
        "        }\n",
        "        for col in CFG['features']['ranker']['time'] + CFG['features']['ranker']['store'] + CFG['features']['ranker']['channel'] + CFG['features']['ranker']['basket']:\n",
        "            if col in agg.columns:\n",
        "                feat[col] = row[col]\n",
        "        # add need-state features\n",
        "        for ccol in ns_df.columns:\n",
        "            feat[ccol] = ns_df.loc[idx, ccol]\n",
        "        feat[f\"promo_type__{p[ptype_col]}\"] = 1\n",
        "        rank_rows.append(feat)\n",
        "\n",
        "rank_infer = pd.DataFrame(rank_rows).fillna(0)\n",
        "# Align column order to ranker_featcols\n",
        "X_rank_infer = np.stack([ [row.get(col, 0) for col in ranker_featcols] for _, row in rank_infer.iterrows() ])\n",
        "\n",
        "scores = ranker_model.predict_proba(X_rank_infer)[:,1] if hasattr(ranker_model, 'predict_proba') else ranker_model.predict(X_rank_infer)\n",
        "rank_infer['score'] = scores\n",
        "print('Built ranking features and scored candidates.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recommendations built. Preview:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transaction_id</th>\n",
              "      <th>promo_id</th>\n",
              "      <th>promo_type</th>\n",
              "      <th>score</th>\n",
              "      <th>ptype_prob</th>\n",
              "      <th>scope_match_score</th>\n",
              "      <th>reason_codes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TX0000309</td>\n",
              "      <td>PR0027</td>\n",
              "      <td>Flash Sale</td>\n",
              "      <td>5.758817e-09</td>\n",
              "      <td>0.090188</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'meets_min_spend': True, 'channel_match': Fal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TX0000309</td>\n",
              "      <td>PR0056</td>\n",
              "      <td>Flash Sale</td>\n",
              "      <td>5.758817e-09</td>\n",
              "      <td>0.090188</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'meets_min_spend': True, 'channel_match': Fal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TX0000309</td>\n",
              "      <td>PR0070</td>\n",
              "      <td>Flash Sale</td>\n",
              "      <td>5.758817e-09</td>\n",
              "      <td>0.090188</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'meets_min_spend': True, 'channel_match': Fal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TX0000384</td>\n",
              "      <td>PR0001</td>\n",
              "      <td>Product_Coupon</td>\n",
              "      <td>6.321599e-09</td>\n",
              "      <td>0.123566</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'meets_min_spend': True, 'channel_match': Fal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TX0000384</td>\n",
              "      <td>PR0003</td>\n",
              "      <td>Product_Coupon</td>\n",
              "      <td>6.321599e-09</td>\n",
              "      <td>0.123566</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'meets_min_spend': True, 'channel_match': Fal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TX0000384</td>\n",
              "      <td>PR0014</td>\n",
              "      <td>Product_Coupon</td>\n",
              "      <td>6.321599e-09</td>\n",
              "      <td>0.123566</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'meets_min_spend': True, 'channel_match': Fal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>TX0000459</td>\n",
              "      <td>PR0066</td>\n",
              "      <td>Buy 1 get 1</td>\n",
              "      <td>9.369385e-09</td>\n",
              "      <td>0.157880</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'meets_min_spend': True, 'channel_match': Fal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>TX0000459</td>\n",
              "      <td>PR0073</td>\n",
              "      <td>Buy 1 get 1</td>\n",
              "      <td>9.369385e-09</td>\n",
              "      <td>0.157880</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'meets_min_spend': True, 'channel_match': Fal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>TX0000459</td>\n",
              "      <td>PR0095</td>\n",
              "      <td>Buy 1 get 1</td>\n",
              "      <td>9.369385e-09</td>\n",
              "      <td>0.157880</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'meets_min_spend': True, 'channel_match': Fal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>TX0000477</td>\n",
              "      <td>PR0003</td>\n",
              "      <td>Product_Coupon</td>\n",
              "      <td>1.046999e-08</td>\n",
              "      <td>0.105884</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'meets_min_spend': True, 'channel_match': Fal...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  transaction_id promo_id      promo_type         score  ptype_prob  \\\n",
              "0      TX0000309   PR0027      Flash Sale  5.758817e-09    0.090188   \n",
              "1      TX0000309   PR0056      Flash Sale  5.758817e-09    0.090188   \n",
              "2      TX0000309   PR0070      Flash Sale  5.758817e-09    0.090188   \n",
              "3      TX0000384   PR0001  Product_Coupon  6.321599e-09    0.123566   \n",
              "4      TX0000384   PR0003  Product_Coupon  6.321599e-09    0.123566   \n",
              "5      TX0000384   PR0014  Product_Coupon  6.321599e-09    0.123566   \n",
              "6      TX0000459   PR0066     Buy 1 get 1  9.369385e-09    0.157880   \n",
              "7      TX0000459   PR0073     Buy 1 get 1  9.369385e-09    0.157880   \n",
              "8      TX0000459   PR0095     Buy 1 get 1  9.369385e-09    0.157880   \n",
              "9      TX0000477   PR0003  Product_Coupon  1.046999e-08    0.105884   \n",
              "\n",
              "   scope_match_score                                       reason_codes  \n",
              "0                0.0  {'meets_min_spend': True, 'channel_match': Fal...  \n",
              "1                0.0  {'meets_min_spend': True, 'channel_match': Fal...  \n",
              "2                0.0  {'meets_min_spend': True, 'channel_match': Fal...  \n",
              "3                0.0  {'meets_min_spend': True, 'channel_match': Fal...  \n",
              "4                0.0  {'meets_min_spend': True, 'channel_match': Fal...  \n",
              "5                0.0  {'meets_min_spend': True, 'channel_match': Fal...  \n",
              "6                0.0  {'meets_min_spend': True, 'channel_match': Fal...  \n",
              "7                0.0  {'meets_min_spend': True, 'channel_match': Fal...  \n",
              "8                0.0  {'meets_min_spend': True, 'channel_match': Fal...  \n",
              "9                0.0  {'meets_min_spend': True, 'channel_match': Fal...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Format output Top-N per basket with reason codes\n",
        "TOPN = int(CFG.get('business',{}).get('topN', 3))\n",
        "\n",
        "rows = []\n",
        "for tid, grp in rank_infer.groupby('transaction_id'):\n",
        "    topk = grp.sort_values('score', ascending=False).head(TOPN)\n",
        "    for _, r in topk.iterrows():\n",
        "        reason = {\n",
        "            'meets_min_spend': bool(r['min_spend_gap'] <= 0),\n",
        "            'channel_match': bool(r['channel_match']),\n",
        "            'within_window': bool(r['within_window']),\n",
        "            'category_overlap': bool(r['scope_match_score'] > 0)\n",
        "        }\n",
        "        rows.append({\n",
        "            'transaction_id': tid,\n",
        "            'promo_id': r['promo_id'],\n",
        "            'promo_type': r['promo_type'],\n",
        "            'score': float(r['score']),\n",
        "            'ptype_prob': float(r['ptype_prob']),\n",
        "            'scope_match_score': float(r['scope_match_score']),\n",
        "            'reason_codes': reason\n",
        "        })\n",
        "\n",
        "recs = pd.DataFrame(rows)\n",
        "print('Recommendations built. Preview:')\n",
        "recs.head(10)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
