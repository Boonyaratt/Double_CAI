{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "456f3b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5e9ba806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9784\\853814542.py:3: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tx_merge = pd.read_csv(BASE/\"tx_merge3.csv\")\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9784\\853814542.py:4: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  promotions = pd.read_csv(BASE/\"promotions.csv\", parse_dates=[\"start_date\",\"end_date\"])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9784\\853814542.py:4: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  promotions = pd.read_csv(BASE/\"promotions.csv\", parse_dates=[\"start_date\",\"end_date\"])\n"
     ]
    }
   ],
   "source": [
    "BASE = Path(\"Datasets/mockup_ver2/\")\n",
    "\n",
    "tx_merge = pd.read_csv(BASE/\"tx_merge3.csv\") \n",
    "promotions = pd.read_csv(BASE/\"promotions.csv\", parse_dates=[\"start_date\",\"end_date\"])\n",
    "\n",
    "promos_df = promotions.copy()\n",
    "df = tx_merge.copy()\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "515fe105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "HAS_LGB = True\n",
    "\n",
    "SEED = 42\n",
    "NEED_K = 8\n",
    "PCA_K  = 30\n",
    "TOPK_TYPES = 2\n",
    "REL_TH = 0.30\n",
    "MAX_CANDS = 40\n",
    "\n",
    "# ---- Columns (อิงจาก tx_merge2.csv ของคุณ) ----\n",
    "COL_TX   = \"transaction_id\"\n",
    "COL_USER = \"user_id\"\n",
    "COL_PROD = \"product_id\"\n",
    "COL_QTY  = \"qty\"\n",
    "COL_PRICE= \"price\"\n",
    "\n",
    "COL_CAT   = \"products.category\"\n",
    "COL_BRAND = \"products.brand\"\n",
    "COL_TS    = \"timestamp\"\n",
    "COL_STORE = \"store_id\"\n",
    "COL_ONLINE= \"is_online\"\n",
    "\n",
    "COL_ORDER_H = \"order_hour\"\n",
    "COL_DOW     = \"dayofweek\"\n",
    "COL_MONTH   = \"month\"\n",
    "COL_DAY     = \"day\"\n",
    "COL_WOY     = \"weekofyear\"\n",
    "COL_QUARTER = \"quarter\"\n",
    "COL_IS_WKD  = \"is_weekend\"\n",
    "COL_THAI_SEAS = \"thai_season\"\n",
    "COL_IN_FEST   = \"InFestival\"\n",
    "\n",
    "COL_WKD_BOOST = \"weekday_boost\"\n",
    "COL_WKE_BOOST = \"weekend_boost\"\n",
    "COL_FES_BOOST = \"festival_boost\"\n",
    "COL_PEAKS     = \"peaks_encoded\"\n",
    "COL_HOUR_W    = \"hour_weight\"\n",
    "COL_LOYALTY   = \"loyalty_score\"\n",
    "COL_EXPECT    = \"expected_basket_items\"\n",
    "COL_ELAS      = \"price_elasticity\"\n",
    "COL_SEGMENT   = \"segment\"\n",
    "\n",
    "# ถ้าใช้ label จาก tx_merge โดยตรง:\n",
    "LABEL_COL_IN_TX = \"promotions.promo_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d4521c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_map = {}\n",
    "if \"promotions.promo_type\" in promos_df.columns:\n",
    "    rename_map[\"promotions.promo_type\"] = \"promo_type\"\n",
    "if \"promotion_category\" in promos_df.columns and \"promo_type\" not in promos_df.columns:\n",
    "    rename_map[\"promotion_category\"] = \"promo_type\"\n",
    "if \"promotion_type\" in promos_df.columns and \"promo_type\" not in promos_df.columns:\n",
    "    rename_map[\"promotion_type\"] = \"promo_type\"\n",
    "if \"scope\" in promos_df.columns and \"product_scope\" not in promos_df.columns:\n",
    "    rename_map[\"scope\"] = \"product_scope\"\n",
    "\n",
    "promos_df = promos_df.rename(columns=rename_map)\n",
    "\n",
    "# เติมคอลัมน์ที่ขาดด้วยค่า default ปลอดภัย\n",
    "defaults = {\n",
    "    \"promo_id\": \"__UNK__\",\n",
    "    \"promo_type\": \"Unknown\",\n",
    "    \"product_scope\": \"\",\n",
    "    \"is_online\": 1,\n",
    "    \"start_date\": pd.Timestamp(\"2000-01-01\"),\n",
    "    \"end_date\":   pd.Timestamp(\"2100-01-01\"),\n",
    "    \"est_margin\": 0.0\n",
    "}\n",
    "for c, d in defaults.items():\n",
    "    if c not in promos_df.columns:\n",
    "        promos_df[c] = d\n",
    "\n",
    "# final check\n",
    "need_cols = [\"promo_id\",\"promo_type\",\"product_scope\",\"is_online\",\"start_date\",\"end_date\",\"est_margin\"]\n",
    "missing = [c for c in need_cols if c not in promos_df.columns]\n",
    "assert not missing, f\"promos_df ขาดคอลัมน์: {missing}\"\n",
    "\n",
    "# แปลงวันที่ (กัน type ผิด)\n",
    "promos_df[\"start_date\"] = pd.to_datetime(promos_df[\"start_date\"], errors=\"coerce\")\n",
    "promos_df[\"end_date\"]   = pd.to_datetime(promos_df[\"end_date\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "672c192b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basket_feat shape: (19178, 85)\n",
      "num FEATURES: 81\n"
     ]
    }
   ],
   "source": [
    "agg = {}\n",
    "if COL_PROD in df.columns: agg[COL_PROD] = \"nunique\"\n",
    "if COL_QTY  in df.columns: agg[COL_QTY]  = \"sum\"\n",
    "if COL_PRICE in df.columns and COL_QTY in df.columns:\n",
    "    df[\"_revenue\"] = df[COL_PRICE].fillna(0) * df[COL_QTY].fillna(0)\n",
    "    agg[\"_revenue\"] = \"sum\"\n",
    "elif COL_PRICE in df.columns:\n",
    "    agg[COL_PRICE] = \"sum\"\n",
    "\n",
    "basket = (\n",
    "    df.groupby(COL_TX).agg(agg)\n",
    "      .rename(columns={COL_PROD: \"basket_unique_items\"})\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "evt = df.groupby(COL_TX)[COL_TS].min().rename(\"event_time\").reset_index()\n",
    "basket = basket.merge(evt, on=COL_TX, how=\"left\")\n",
    "\n",
    "# context ที่มีอยู่แล้วในไฟล์\n",
    "context_cols = [\n",
    "    COL_STORE, COL_ONLINE,\n",
    "    COL_ORDER_H, COL_DOW, COL_MONTH, COL_DAY, COL_WOY, COL_QUARTER,\n",
    "    COL_IS_WKD, COL_THAI_SEAS, COL_IN_FEST,\n",
    "    COL_WKD_BOOST, COL_WKE_BOOST, COL_FES_BOOST, COL_PEAKS, COL_HOUR_W,\n",
    "    COL_LOYALTY, COL_EXPECT, COL_ELAS, COL_SEGMENT\n",
    "]\n",
    "for c in context_cols:\n",
    "    if c in df.columns:\n",
    "        first = df.groupby(COL_TX)[c].first().reset_index()\n",
    "        basket = basket.merge(first, on=COL_TX, how=\"left\")\n",
    "\n",
    "# multi-hot: k=category/brand proportions\n",
    "def crosstab_prop(frame, key, val, prefix):\n",
    "    if val not in frame.columns:\n",
    "        return pd.DataFrame({key: frame[key].unique()})\n",
    "    ct = pd.crosstab(frame[key], frame[val])\n",
    "    if ct.empty:\n",
    "        return pd.DataFrame({key: frame[key].unique()})\n",
    "    prop = ct.div(ct.sum(axis=1).replace(0, np.nan), axis=0).fillna(0)\n",
    "    prop.columns = [f\"{prefix}={c}\" for c in prop.columns]\n",
    "    return prop.reset_index()\n",
    "\n",
    "cat_prop   = crosstab_prop(df, COL_TX, COL_CAT,   \"cat\")\n",
    "brand_prop = crosstab_prop(df, COL_TX, COL_BRAND, \"brand\")\n",
    "basket = basket.merge(cat_prop, on=COL_TX, how=\"left\").merge(brand_prop, on=COL_TX, how=\"left\")\n",
    "\n",
    "if COL_ONLINE in basket.columns:\n",
    "    basket[COL_ONLINE] = basket[COL_ONLINE].astype(int)\n",
    "\n",
    "comp_cols = [c for c in basket.columns if c.startswith(\"cat=\") or c.startswith(\"brand=\")]\n",
    "num_cols = [\n",
    "    \"basket_unique_items\", COL_QTY, \"_revenue\", COL_PRICE,\n",
    "    COL_ORDER_H, COL_DOW, COL_MONTH, COL_DAY, COL_WOY, COL_QUARTER,\n",
    "    COL_IS_WKD, COL_THAI_SEAS, COL_IN_FEST, COL_WKD_BOOST, COL_WKE_BOOST, COL_FES_BOOST,\n",
    "    COL_PEAKS, COL_HOUR_W, COL_LOYALTY, COL_EXPECT, COL_ELAS\n",
    "]\n",
    "num_cols = [c for c in num_cols if c in basket.columns]\n",
    "\n",
    "FEATURE_COLS = num_cols + ([COL_ONLINE] if COL_ONLINE in basket.columns else []) + comp_cols\n",
    "basket_feat = basket.copy()\n",
    "\n",
    "# sanity print\n",
    "print(\"basket_feat shape:\", basket_feat.shape)\n",
    "print(\"num FEATURES:\", len(FEATURE_COLS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0ed17d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_types(probs, classes, k=2, ensure_non_nopromo=2, nopromo_label=\"NoPromo\"):\n",
    "    \"\"\"\n",
    "    เลือกประเภทโปรฯ สำหรับ recall: บังคับให้มีอย่างน้อย ensure_non_nopromo ประเภทที่ไม่ใช่ NoPromo\n",
    "    แล้วค่อยเติม NoPromo ในลิสต์ (ถ้าจำเป็น)\n",
    "    \"\"\"\n",
    "    order = np.argsort(probs)[::-1]\n",
    "    cls_order = [classes[i] for i in order]\n",
    "\n",
    "    non_np = [c for c in cls_order if c != nopromo_label]\n",
    "    top_non_np = non_np[:max(ensure_non_nopromo, 1)]\n",
    "\n",
    "    merged, seen = [], set()\n",
    "    for c in top_non_np + cls_order:\n",
    "        if c not in seen:\n",
    "            merged.append(c); seen.add(c)\n",
    "        if len(merged) >= k + 1:  # เผื่อ 1 ช่องให้ NoPromo\n",
    "            break\n",
    "\n",
    "    if nopromo_label not in merged:\n",
    "        merged.append(nopromo_label)\n",
    "\n",
    "    return merged[:k+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1ded4372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette(sample): 0.081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>need_state_cluster</th>\n",
       "      <th>count</th>\n",
       "      <th>share_pct</th>\n",
       "      <th>basket_unique_items</th>\n",
       "      <th>qty</th>\n",
       "      <th>_revenue</th>\n",
       "      <th>order_hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>InFestival</th>\n",
       "      <th>weekday_boost</th>\n",
       "      <th>weekend_boost</th>\n",
       "      <th>festival_boost</th>\n",
       "      <th>hour_weight</th>\n",
       "      <th>loyalty_score</th>\n",
       "      <th>expected_basket_items</th>\n",
       "      <th>price_elasticity</th>\n",
       "      <th>top_components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5697</td>\n",
       "      <td>29.71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.906</td>\n",
       "      <td>870.099</td>\n",
       "      <td>11.645</td>\n",
       "      <td>3.034</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.923</td>\n",
       "      <td>2.989</td>\n",
       "      <td>0.010</td>\n",
       "      <td>cat=Snacks:718.0; cat=HealthBeauty:694.0; cat=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2286</td>\n",
       "      <td>11.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.961</td>\n",
       "      <td>895.440</td>\n",
       "      <td>11.461</td>\n",
       "      <td>3.029</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.087</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.924</td>\n",
       "      <td>2.989</td>\n",
       "      <td>0.007</td>\n",
       "      <td>cat=ReadyToEat:294.0; cat=Snacks:277.0; cat=He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3179</td>\n",
       "      <td>16.58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.928</td>\n",
       "      <td>823.406</td>\n",
       "      <td>11.306</td>\n",
       "      <td>3.014</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.014</td>\n",
       "      <td>1.015</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.924</td>\n",
       "      <td>2.989</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>cat=ReadyToEat:434.0; cat=Snacks:397.0; cat=He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3344</td>\n",
       "      <td>17.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.936</td>\n",
       "      <td>869.680</td>\n",
       "      <td>11.576</td>\n",
       "      <td>3.045</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.081</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.050</td>\n",
       "      <td>1.050</td>\n",
       "      <td>1.004</td>\n",
       "      <td>0.923</td>\n",
       "      <td>2.989</td>\n",
       "      <td>0.007</td>\n",
       "      <td>cat=ReadyToEat:454.0; cat=Snacks:442.0; cat=In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1348</td>\n",
       "      <td>7.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.649</td>\n",
       "      <td>2602.580</td>\n",
       "      <td>11.456</td>\n",
       "      <td>2.832</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986</td>\n",
       "      <td>1.015</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.924</td>\n",
       "      <td>2.990</td>\n",
       "      <td>0.028</td>\n",
       "      <td>cat=Others:1181.0; brand=Brand_028:172.0; bran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>632</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.111</td>\n",
       "      <td>1130.049</td>\n",
       "      <td>11.601</td>\n",
       "      <td>2.968</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989</td>\n",
       "      <td>1.021</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.922</td>\n",
       "      <td>2.990</td>\n",
       "      <td>0.004</td>\n",
       "      <td>brand=Brand_013:632.0; cat=Household:146.0; ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>521</td>\n",
       "      <td>2.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.940</td>\n",
       "      <td>842.697</td>\n",
       "      <td>11.388</td>\n",
       "      <td>2.917</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.924</td>\n",
       "      <td>2.989</td>\n",
       "      <td>0.013</td>\n",
       "      <td>brand=Brand_040:521.0; cat=Household:172.0; ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2171</td>\n",
       "      <td>11.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.961</td>\n",
       "      <td>930.578</td>\n",
       "      <td>11.246</td>\n",
       "      <td>2.953</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.068</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.100</td>\n",
       "      <td>1.100</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.923</td>\n",
       "      <td>2.989</td>\n",
       "      <td>0.008</td>\n",
       "      <td>cat=HealthBeauty:259.0; cat=ReadyToEat:249.0; ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   need_state_cluster  count  share_pct  basket_unique_items    qty  _revenue  \\\n",
       "0                   0   5697      29.71                  1.0  2.906   870.099   \n",
       "1                   1   2286      11.92                  1.0  2.961   895.440   \n",
       "2                   2   3179      16.58                  1.0  2.928   823.406   \n",
       "3                   3   3344      17.44                  1.0  2.936   869.680   \n",
       "4                   4   1348       7.03                  1.0  3.649  2602.580   \n",
       "5                   5    632       3.30                  1.0  3.111  1130.049   \n",
       "6                   6    521       2.72                  1.0  2.940   842.697   \n",
       "7                   7   2171      11.32                  1.0  2.961   930.578   \n",
       "\n",
       "   order_hour  dayofweek  is_weekend  InFestival  weekday_boost  \\\n",
       "0      11.645      3.034       0.286       0.079            1.0   \n",
       "1      11.461      3.029       0.294       0.087            1.0   \n",
       "2      11.306      3.014       0.282       0.074            1.0   \n",
       "3      11.576      3.045       0.295       0.081            1.0   \n",
       "4      11.456      2.832       0.260       0.083            1.0   \n",
       "5      11.601      2.968       0.291       0.076            1.0   \n",
       "6      11.388      2.917       0.271       0.075            1.0   \n",
       "7      11.246      2.953       0.275       0.068            1.0   \n",
       "\n",
       "   weekend_boost  festival_boost  hour_weight  loyalty_score  \\\n",
       "0          0.892           0.980        1.000          0.923   \n",
       "1          1.000           1.000        0.995          0.924   \n",
       "2          1.014           1.015        0.992          0.924   \n",
       "3          1.050           1.050        1.004          0.923   \n",
       "4          0.986           1.015        0.994          0.924   \n",
       "5          0.989           1.021        0.988          0.922   \n",
       "6          0.991           1.020        0.992          0.924   \n",
       "7          1.100           1.100        0.997          0.923   \n",
       "\n",
       "   expected_basket_items  price_elasticity  \\\n",
       "0                  2.989             0.010   \n",
       "1                  2.989             0.007   \n",
       "2                  2.989            -0.008   \n",
       "3                  2.989             0.007   \n",
       "4                  2.990             0.028   \n",
       "5                  2.990             0.004   \n",
       "6                  2.989             0.013   \n",
       "7                  2.989             0.008   \n",
       "\n",
       "                                      top_components  \n",
       "0  cat=Snacks:718.0; cat=HealthBeauty:694.0; cat=...  \n",
       "1  cat=ReadyToEat:294.0; cat=Snacks:277.0; cat=He...  \n",
       "2  cat=ReadyToEat:434.0; cat=Snacks:397.0; cat=He...  \n",
       "3  cat=ReadyToEat:454.0; cat=Snacks:442.0; cat=In...  \n",
       "4  cat=Others:1181.0; brand=Brand_028:172.0; bran...  \n",
       "5  brand=Brand_013:632.0; cat=Household:146.0; ca...  \n",
       "6  brand=Brand_040:521.0; cat=Household:172.0; ca...  \n",
       "7  cat=HealthBeauty:259.0; cat=ReadyToEat:249.0; ...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% Need-state discovery (fixed: auto-encode non-numeric) \n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# ทำ one-hot ให้ทุกคอลัมน์ที่เป็น object/category (กัน error 'Rainy')\n",
    "X_df = basket_feat[FEATURE_COLS].copy()\n",
    "\n",
    "# bool -> int\n",
    "bool_cols = X_df.select_dtypes(include=[\"bool\"]).columns\n",
    "if len(bool_cols):\n",
    "    X_df[bool_cols] = X_df[bool_cols].astype(int)\n",
    "\n",
    "obj_cols = X_df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "if len(obj_cols):\n",
    "    X_df = pd.get_dummies(X_df, columns=obj_cols, dummy_na=True)\n",
    "\n",
    "X = X_df.fillna(0.0).astype(float).values\n",
    "\n",
    "# Scale + PCA\n",
    "sc = StandardScaler()\n",
    "Xs = sc.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=min(PCA_K, Xs.shape[1]), random_state=SEED)\n",
    "Xp  = pca.fit_transform(Xs)\n",
    "\n",
    "# KMeans\n",
    "mbk = MiniBatchKMeans(n_clusters=NEED_K, random_state=SEED, batch_size=4096, n_init=10)\n",
    "labels = mbk.fit_predict(Xp)\n",
    "basket_feat[\"need_state_cluster\"] = labels\n",
    "\n",
    "# silhouette (sample)\n",
    "try:\n",
    "    idx = np.random.RandomState(SEED).choice(len(Xp), size=min(5000, len(Xp)), replace=False)\n",
    "    sil = silhouette_score(Xp[idx], labels[idx])\n",
    "except Exception:\n",
    "    sil = np.nan\n",
    "print(f\"Silhouette(sample): {sil:.3f}\")\n",
    "\n",
    "# profiling\n",
    "prof_cols = [\n",
    "    \"basket_unique_items\", COL_QTY, COL_PRICE, \"_revenue\",\n",
    "    COL_ORDER_H, COL_DOW, COL_IS_WKD, COL_THAI_SEAS, COL_IN_FEST,\n",
    "    COL_WKD_BOOST, COL_WKE_BOOST, COL_FES_BOOST, COL_HOUR_W,\n",
    "    COL_LOYALTY, COL_EXPECT, COL_ELAS\n",
    "]\n",
    "prof_cols = [c for c in prof_cols if c in basket_feat.columns]\n",
    "\n",
    "def top_components(df_in, key, cols, n=8):\n",
    "    rows = []\n",
    "    for k, grp in df_in.groupby(key):\n",
    "        sums = grp[cols].sum().sort_values(ascending=False)\n",
    "        rows.append({key: k, \"top_components\": \"; \".join([f\"{c}:{sums[c]:.1f}\" for c in sums.index[:n]])})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "comp_cols = [c for c in basket_feat.columns if c.startswith(\"cat=\") or c.startswith(\"brand=\")]\n",
    "prof = (\n",
    "    basket_feat.groupby(\"need_state_cluster\")[prof_cols]\n",
    "    .mean(numeric_only=True).round(3).reset_index()\n",
    ")\n",
    "topc = top_components(basket_feat, \"need_state_cluster\", comp_cols, n=8) if comp_cols else pd.DataFrame(columns=[\"need_state_cluster\",\"top_components\"])\n",
    "\n",
    "need_profile = prof.merge(topc, on=\"need_state_cluster\", how=\"left\")\n",
    "need_profile.insert(1, \"count\", basket_feat.groupby(\"need_state_cluster\")[COL_TX].nunique().values)\n",
    "need_profile.insert(2, \"share_pct\", (need_profile[\"count\"]/need_profile[\"count\"].sum()*100).round(2))\n",
    "\n",
    "need_profile.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3b93423d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation report (P(type|X))\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Brandday       0.00      0.00      0.00         0\n",
      "   Buy 1 get 1       0.00      0.00      0.00         0\n",
      "    Flash Sale       0.00      0.00      0.00         0\n",
      "     Mega Sale       0.00      0.00      0.00         0\n",
      "       NoPromo       1.00      0.95      0.97      3836\n",
      "Product_Coupon       0.00      0.00      0.00         0\n",
      "\n",
      "      accuracy                           0.95      3836\n",
      "     macro avg       0.17      0.16      0.16      3836\n",
      "  weighted avg       1.00      0.95      0.97      3836\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# เตรียม label ต่อธุรกรรมจาก tx_merge โดยตรง (ถ้าไม่มี ใช้วิธี join ผ่าน promo_id แทน)\n",
    "if LABEL_COL_IN_TX not in tx_merge.columns:\n",
    "    raise ValueError(f\"ไม่พบ {LABEL_COL_IN_TX} ใน tx_merge\")\n",
    "\n",
    "label_df = (\n",
    "    tx_merge.groupby(COL_TX)[LABEL_COL_IN_TX].first().reset_index()\n",
    "    .rename(columns={LABEL_COL_IN_TX:\"used_type\"})\n",
    ")\n",
    "label_df[\"used_type\"] = label_df[\"used_type\"].fillna(\"NoPromo\")\n",
    "\n",
    "data_ptype = basket_feat.merge(label_df, on=COL_TX, how=\"left\")\n",
    "data_ptype[\"used_type\"] = data_ptype[\"used_type\"].fillna(\"NoPromo\")\n",
    "\n",
    "# one-hot ฟีเจอร์สำหรับทั้งชุด → คอลัมน์จะตรงกันแน่นอน\n",
    "X_all = data_ptype[FEATURE_COLS].copy()\n",
    "\n",
    "bool_cols = X_all.select_dtypes(include=[\"bool\"]).columns\n",
    "if len(bool_cols):\n",
    "    X_all[bool_cols] = X_all[bool_cols].astype(int)\n",
    "\n",
    "obj_cols = X_all.select_dtypes(include=[\"object\",\"category\"]).columns\n",
    "if len(obj_cols):\n",
    "    X_all = pd.get_dummies(X_all, columns=obj_cols, dummy_na=True)\n",
    "\n",
    "X_all = X_all.fillna(0.0).astype(float)\n",
    "\n",
    "# split ตามเวลา\n",
    "if \"event_time\" in data_ptype.columns and data_ptype[\"event_time\"].notna().any():\n",
    "    data_ptype = data_ptype.sort_values(\"event_time\")\n",
    "    X_all = X_all.loc[data_ptype.index]\n",
    "    cut = int(len(data_ptype)*0.8)\n",
    "    tr_idx = data_ptype.index[:cut]\n",
    "    va_idx = data_ptype.index[cut:]\n",
    "else:\n",
    "    tr_idx, va_idx = train_test_split(\n",
    "        data_ptype.index, test_size=0.2, random_state=SEED, stratify=data_ptype[\"used_type\"]\n",
    "    )\n",
    "\n",
    "Xtr = X_all.loc[tr_idx].values\n",
    "Xva = X_all.loc[va_idx].values\n",
    "ytr = data_ptype.loc[tr_idx, \"used_type\"].values\n",
    "yva = data_ptype.loc[va_idx, \"used_type\"].values\n",
    "\n",
    "classes = np.unique(data_ptype[\"used_type\"].values)\n",
    "class_to_idx = {c:i for i,c in enumerate(classes)}\n",
    "ytr_idx = np.array([class_to_idx[c] for c in ytr])\n",
    "yva_idx = np.array([class_to_idx[c] for c in yva])\n",
    "\n",
    "# base model + calibration (รองรับหลายเวอร์ชัน sklearn)\n",
    "if HAS_LGB:\n",
    "    base = lgb.LGBMClassifier(\n",
    "        objective=\"multiclass\",\n",
    "        num_class=len(classes),\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=63,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=SEED\n",
    "    )\n",
    "else:\n",
    "    base = GradientBoostingClassifier(random_state=SEED)\n",
    "\n",
    "try:\n",
    "    ptype_model = CalibratedClassifierCV(estimator=base, method=\"sigmoid\", cv=3)\n",
    "except TypeError:\n",
    "    ptype_model = CalibratedClassifierCV(base_estimator=base, method=\"sigmoid\", cv=3)\n",
    "\n",
    "ptype_model.fit(Xtr, ytr_idx)\n",
    "pred = ptype_model.predict(Xva)\n",
    "print(\"Validation report (P(type|X))\")\n",
    "print(classification_report(yva_idx, pred, target_names=list(classes)))\n",
    "\n",
    "ptype_classes  = list(classes)\n",
    "ptype_featcols = list(X_all.columns)  # สำคัญ: ใช้ตอน inference ต้อง align คอลัมน์ชุดนี้\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fa789576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features_for_ptype(row_series, raw_feature_cols, feat_cols_all):\n",
    "    row_df = pd.DataFrame([row_series[raw_feature_cols]])\n",
    "    # bool -> int\n",
    "    bool_cols = row_df.select_dtypes(include=[\"bool\"]).columns\n",
    "    if len(bool_cols):\n",
    "        row_df[bool_cols] = row_df[bool_cols].astype(int)\n",
    "    # one-hot สำหรับ object/category\n",
    "    obj_cols = row_df.select_dtypes(include=[\"object\",\"category\"]).columns\n",
    "    if len(obj_cols):\n",
    "        row_df = pd.get_dummies(row_df, columns=obj_cols, dummy_na=True)\n",
    "    # align columns\n",
    "    for c in feat_cols_all:\n",
    "        if c not in row_df.columns:\n",
    "            row_df[c] = 0.0\n",
    "    row_df = row_df[feat_cols_all].fillna(0.0).astype(float)\n",
    "    return row_df.values  # shape (1, d)\n",
    "\n",
    "def eligibility_filter(promos_df, context_row, now):\n",
    "    out = promos_df.copy()\n",
    "    if \"start_date\" in out.columns:\n",
    "        out[\"start_date\"] = pd.to_datetime(out[\"start_date\"], errors=\"coerce\")\n",
    "    if \"end_date\" in out.columns:\n",
    "        out[\"end_date\"] = pd.to_datetime(out[\"end_date\"], errors=\"coerce\")\n",
    "    if \"is_online\" in out.columns and COL_ONLINE in context_row.index:\n",
    "        out = out[out[\"is_online\"] == int(context_row[COL_ONLINE])]\n",
    "    if \"start_date\" in out.columns and \"end_date\" in out.columns and pd.notna(now):\n",
    "        out = out[(out[\"start_date\"] <= now) & (now <= out[\"end_date\"])]\n",
    "    return out\n",
    "\n",
    "# แทนที่ฟังก์ชันเดิมทั้งก้อน\n",
    "def simple_scope_relevance(basket_row, promo_row):\n",
    "    \"\"\"\n",
    "    คำนวณความเกี่ยวข้องระหว่างโปรกับตะกร้า\n",
    "    - ถ้า product_scope มี category/code: วัด Jaccard กับ cat=... ในบิล\n",
    "    - ถ้า scope ว่าง: ลดน้ำหนักลง ตามความนิยมของหมวดในบิล (ไม่ใช่ 0.5 ตายตัว)\n",
    "    \"\"\"\n",
    "    scope_raw = str(promo_row.get(\"product_scope\", \"\") or \"\").strip().lower()\n",
    "    # ดึงหมวดในบิล (จากฟีเจอร์ cat=... ที่เป็นสัดส่วน)\n",
    "    basket_cats = {col.split(\"cat=\")[1].lower() for col in basket_row.index\n",
    "                   if isinstance(col, str) and col.startswith(\"cat=\") and float(basket_row[col]) > 0}\n",
    "\n",
    "    if not basket_cats:\n",
    "        return 0.15  # ไม่มีสัดส่วนหมวด → ให้ต่ำหน่อย\n",
    "\n",
    "    # เคสมี scope → tokenize เป็นชุดคำ (รองรับ comma, ;, space)\n",
    "    if scope_raw:\n",
    "        sep = [\",\",\";\",\"|\",\"/\"]\n",
    "        for s in sep: scope_raw = scope_raw.replace(s, \" \")\n",
    "        scope_set = {tok for tok in scope_raw.split() if tok}\n",
    "        if not scope_set:\n",
    "            return 0.2\n",
    "        inter = len(basket_cats & scope_set)\n",
    "        union = len(basket_cats | scope_set)\n",
    "        j = inter/union if union else 0.0\n",
    "        # เพิ่ม boost ถ้า inter>0\n",
    "        bonus = 0.2 if inter > 0 else 0.0\n",
    "        return min(1.0, 0.3 + 0.7*j + bonus)\n",
    "\n",
    "    # เคส scope ว่าง → ให้คะแนนตามความ “กระจุกตัว” ของหมวดในบิล\n",
    "    # ยิ่งบิลมี 1-2 หมวดหลักชัดเจน → relevance สูงขึ้น (โปรจับหมวดกว้างก็ยังพอเวิร์ก)\n",
    "    cat_share = [float(basket_row[c]) for c in basket_row.index\n",
    "                 if isinstance(c, str) and c.startswith(\"cat=\")]\n",
    "    if not cat_share:\n",
    "        return 0.2\n",
    "    top_share = sorted(cat_share, reverse=True)[:2]\n",
    "    focus = sum(top_share)  # ~ 0.6–1.0 ถ้าบิลโฟกัสหมวดชัด\n",
    "    return max(0.2, min(0.7, 0.3 + 0.4*focus))\n",
    "\n",
    "\n",
    "def recall_candidates_for_event_relaxed(\n",
    "    basket_row,\n",
    "    promos_df,\n",
    "    probs, classes,\n",
    "    topk_types=2,\n",
    "    relevance_thresh=0.30,\n",
    "    nopromo_label=\"NoPromo\"\n",
    "):\n",
    "    # 2.1 เลือกประเภท robust\n",
    "    top_types = get_top_types(probs, classes, k=topk_types, ensure_non_nopromo=2, nopromo_label=nopromo_label)\n",
    "    now = basket_row.get(\"event_time\", pd.NaT)\n",
    "\n",
    "    def _elig(df, strict_online=True):\n",
    "        out = df.copy()\n",
    "        if \"start_date\" in out.columns and \"end_date\" in out.columns and pd.notna(now):\n",
    "            out = out[(out[\"start_date\"] <= now) & (now <= out[\"end_date\"])]\n",
    "        if strict_online and \"is_online\" in out.columns and \"is_online\" in basket_row.index:\n",
    "            out = out[out[\"is_online\"] == int(basket_row[\"is_online\"])]\n",
    "        return out\n",
    "\n",
    "    def _score_scope(df_):\n",
    "        df_ = df_.copy()\n",
    "        df_[\"scope_relevance\"] = df_.apply(lambda r: simple_scope_relevance(basket_row, r), axis=1)\n",
    "        return df_\n",
    "\n",
    "    # Stage 1: เข้มที่สุด — date+channel + type filter\n",
    "    cand = _elig(promos_df, strict_online=True)\n",
    "    if \"promo_type\" in cand.columns:\n",
    "        cand = cand[cand[\"promo_type\"].isin(top_types)]\n",
    "    cand = _score_scope(cand)\n",
    "    out = cand[cand[\"scope_relevance\"] >= relevance_thresh]\n",
    "\n",
    "    # Stage 2: ผ่อน channel (online/offline)\n",
    "    if out.empty:\n",
    "        cand2 = _elig(promos_df, strict_online=False)\n",
    "        if \"promo_type\" in cand2.columns:\n",
    "            cand2 = cand2[cand2[\"promo_type\"].isin(top_types)]\n",
    "        cand2 = _score_scope(cand2)\n",
    "        out = cand2[cand2[\"scope_relevance\"] >= max(0.2, relevance_thresh*0.75)]\n",
    "\n",
    "    # Stage 3: ผ่อน type filter (เลือกตาม scope สูงสุดแทน)\n",
    "    if out.empty:\n",
    "        cand3 = _elig(promos_df, strict_online=False)\n",
    "        cand3 = _score_scope(cand3)\n",
    "        out = cand3.nlargest(20, \"scope_relevance\")  # ดึงมาบางส่วนให้มีตัวเลือก\n",
    "\n",
    "    # เติม NoPromo ไว้เป็น baseline เสมอ\n",
    "    nopromo = pd.DataFrame([{\n",
    "        \"promo_id\": \"__NOPROMO__\", \"promo_type\": nopromo_label,\n",
    "        \"product_scope\": \"\", \"est_margin\": 0.0, \"scope_relevance\": 0.0\n",
    "    }])\n",
    "    return pd.concat([out, nopromo], ignore_index=True).drop_duplicates(subset=[\"promo_id\"], keep=\"first\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ba9e509d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>promo_id</th>\n",
       "      <th>promo_type</th>\n",
       "      <th>ptype_prob</th>\n",
       "      <th>scope_relevance</th>\n",
       "      <th>est_margin</th>\n",
       "      <th>is_online</th>\n",
       "      <th>order_hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>need_state_cluster</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PMTX0000001</td>\n",
       "      <td>PR0005</td>\n",
       "      <td>Buy 1 get 1</td>\n",
       "      <td>0.832334</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PMTX0000001</td>\n",
       "      <td>PR0009</td>\n",
       "      <td>Buy 1 get 1</td>\n",
       "      <td>0.832334</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PMTX0000001</td>\n",
       "      <td>PR0021</td>\n",
       "      <td>Buy 1 get 1</td>\n",
       "      <td>0.832334</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PMTX0000001</td>\n",
       "      <td>PR0030</td>\n",
       "      <td>Buy 1 get 1</td>\n",
       "      <td>0.832334</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PMTX0000001</td>\n",
       "      <td>PR0034</td>\n",
       "      <td>Buy 1 get 1</td>\n",
       "      <td>0.832334</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      event_id promo_id   promo_type  ptype_prob  scope_relevance  est_margin  \\\n",
       "0  PMTX0000001   PR0005  Buy 1 get 1    0.832334              0.7         0.0   \n",
       "1  PMTX0000001   PR0009  Buy 1 get 1    0.832334              0.7         0.0   \n",
       "2  PMTX0000001   PR0021  Buy 1 get 1    0.832334              0.7         0.0   \n",
       "3  PMTX0000001   PR0030  Buy 1 get 1    0.832334              0.7         0.0   \n",
       "4  PMTX0000001   PR0034  Buy 1 get 1    0.832334              0.7         0.0   \n",
       "\n",
       "   is_online  order_hour  dayofweek  need_state_cluster  label  \n",
       "0          0           9          0                   0      1  \n",
       "1          0           9          0                   0      1  \n",
       "2          0           9          0                   0      1  \n",
       "3          0           9          0                   0      1  \n",
       "4          0           9          0                   0      1  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_ranking_frame(basket_feats, ptype_model, ptype_classes, ptype_featcols,\n",
    "                        promos_df, label_df, topk=TOPK_TYPES, max_cands=MAX_CANDS):\n",
    "    class_to_idx = {c:i for i,c in enumerate(ptype_classes)}\n",
    "    data = basket_feats.merge(label_df, on=COL_TX, how=\"left\")\n",
    "    data[\"used_type\"] = data[\"used_type\"].fillna(\"NoPromo\")\n",
    "\n",
    "    rows = []\n",
    "    for _, row in data.iterrows():\n",
    "        # encode ให้คอลัมน์ one-hot ตรงกับตอนเทรน\n",
    "        X = encode_features_for_ptype(row, FEATURE_COLS, ptype_featcols)\n",
    "        probs = ptype_model.predict_proba(X)[0]\n",
    "\n",
    "        cands = recall_candidates_for_event_relaxed(\n",
    "            basket_row=row,\n",
    "            promos_df=promos_df,\n",
    "            probs=probs,\n",
    "            classes=ptype_classes,\n",
    "            topk_types=TOPK_TYPES,\n",
    "            relevance_thresh=REL_TH,\n",
    "            nopromo_label=\"NoPromo\"\n",
    "        )\n",
    "\n",
    "        if len(cands) > max_cands:\n",
    "            cands = pd.concat([\n",
    "                cands.nlargest(max_cands//2, \"scope_relevance\"),\n",
    "                cands.sample(n=max_cands-(max_cands//2), random_state=SEED, replace=False)\n",
    "            ])\n",
    "\n",
    "        used_type = row[\"used_type\"]\n",
    "        for _, pr in cands.iterrows():\n",
    "            label = 1 if (pr[\"promo_type\"] == used_type or (used_type==\"NoPromo\" and pr[\"promo_id\"]==\"__NOPROMO__\")) else 0\n",
    "            rows.append({\n",
    "                \"event_id\": row[COL_TX],\n",
    "                \"promo_id\": pr[\"promo_id\"],\n",
    "                \"promo_type\": pr[\"promo_type\"],\n",
    "                \"ptype_prob\": float(probs[class_to_idx.get(pr[\"promo_type\"], class_to_idx.get(\"NoPromo\", 0))]),\n",
    "                \"scope_relevance\": pr.get(\"scope_relevance\", 0.0),\n",
    "                \"est_margin\": pr.get(\"est_margin\", 0.0),\n",
    "                \"is_online\": row.get(COL_ONLINE, 0),\n",
    "                \"order_hour\": row.get(COL_ORDER_H, 0),\n",
    "                \"dayofweek\": row.get(COL_DOW, 0),\n",
    "                \"need_state_cluster\": row.get(\"need_state_cluster\", 0),\n",
    "                \"label\": label\n",
    "            })\n",
    "    rank_df = pd.DataFrame(rows)\n",
    "\n",
    "    # cap negatives per event\n",
    "    out = []\n",
    "    for eid, grp in rank_df.groupby(\"event_id\"):\n",
    "        pos = grp[grp[\"label\"]==1]\n",
    "        neg = grp[grp[\"label\"]==0]\n",
    "        keep_neg = neg if len(neg) <= (max_cands - len(pos)) else neg.sample(n=max_cands - len(pos), random_state=SEED)\n",
    "        out.append(pd.concat([pos, keep_neg], ignore_index=True))\n",
    "    return pd.concat(out, ignore_index=True)\n",
    "\n",
    "rank_df = build_ranking_frame(\n",
    "    basket_feats=basket_feat,\n",
    "    ptype_model=ptype_model,\n",
    "    ptype_classes=ptype_classes,\n",
    "    ptype_featcols=ptype_featcols,\n",
    "    promos_df=promos_df,\n",
    "    label_df=label_df,\n",
    "    topk=TOPK_TYPES,\n",
    "    max_cands=MAX_CANDS\n",
    ")\n",
    "rank_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c70ffefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# หลังสร้าง rank_df = pd.DataFrame(rows)\n",
    "# bring event_time\n",
    "rank_df = rank_df.merge(\n",
    "    basket_feat[[COL_TX, \"event_time\"]].drop_duplicates(),\n",
    "    left_on=\"event_id\", right_on=COL_TX, how=\"left\"\n",
    ").drop(columns=[COL_TX])\n",
    "\n",
    "# parse dates\n",
    "for c in [\"start_date\",\"end_date\"]:\n",
    "    if c in rank_df.columns:\n",
    "        rank_df[c] = pd.to_datetime(rank_df[c], errors=\"coerce\")\n",
    "\n",
    "# new features (เหมือน patch ด้านบน)\n",
    "rank_df[\"discount_norm\"] = (rank_df[\"discount\"].astype(float).fillna(0) / 100.0) if \"discount\" in rank_df.columns else 0.0\n",
    "\n",
    "rank_df[\"is_active_now\"] = (\n",
    "    (rank_df[\"start_date\"] <= rank_df[\"event_time\"]) &\n",
    "    (rank_df[\"event_time\"] <= rank_df[\"end_date\"])\n",
    ").astype(int) if {\"start_date\",\"end_date\",\"event_time\"}.issubset(rank_df.columns) else 1\n",
    "\n",
    "rank_df[\"days_to_end\"] = (\n",
    "    (rank_df[\"end_date\"] - rank_df[\"event_time\"]).dt.days.fillna(0).clip(lower=-365, upper=365)\n",
    ") if {\"end_date\",\"event_time\"}.issubset(rank_df.columns) else 0\n",
    "\n",
    "rank_df[\"type_dup_penalty\"] = (\n",
    "    rank_df.groupby([\"event_id\",\"promo_type\"])[\"promo_id\"].transform(\"count\") - 1\n",
    ").clip(lower=0).fillna(0)\n",
    "\n",
    "rank_df[\"dup_product_penalty\"] = (\n",
    "    rank_df.groupby([\"event_id\",\"product_id\"])[\"promo_id\"].transform(\"count\") - 1\n",
    ").clip(lower=0).fillna(0) if \"product_id\" in rank_df.columns else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "78311745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's ndcg@3: 1\ttrain's ndcg@5: 1\tvalid's ndcg@3: 0.999218\tvalid's ndcg@5: 0.999218\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttrain's ndcg@3: 0.99987\ttrain's ndcg@5: 0.99987\tvalid's ndcg@3: 0.999479\tvalid's ndcg@5: 0.999479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ndcg@3': 0.48096976016684045, 'ndcg@5': 0.48096976016684045}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ndcg_at_k(rels, k=5):\n",
    "    rels = np.asfarray(rels)[:k]\n",
    "    if rels.size == 0: return 0.0\n",
    "    dcg = np.sum((2**rels - 1) / np.log2(np.arange(2, rels.size + 2)))\n",
    "    ideal = np.sort(rels)[::-1]\n",
    "    idcg = np.sum((2**ideal - 1) / np.log2(np.arange(2, ideal.size + 2)))\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def train_ranker(rank_df, k_list=(3,5)):\n",
    "    F = [\"ptype_prob\",\"scope_relevance\",\"est_margin\",\n",
    "     \"discount_norm\",\"is_active_now\",\"days_to_end\",\n",
    "     \"type_dup_penalty\",\"dup_product_penalty\",\n",
    "     \"is_online\",\"order_hour\",\"dayofweek\",\"need_state_cluster\"]\n",
    "\n",
    "    ev = rank_df[\"event_id\"].unique()\n",
    "    tr_e, va_e = train_test_split(ev, test_size=0.2, random_state=SEED)\n",
    "    tr = rank_df[rank_df[\"event_id\"].isin(tr_e)]\n",
    "    va = rank_df[rank_df[\"event_id\"].isin(va_e)]\n",
    "\n",
    "    def to_group(df_):\n",
    "        grp_sizes = df_.groupby(\"event_id\").size().values\n",
    "        X = df_[F].fillna(0).values\n",
    "        y = df_[\"label\"].values\n",
    "        return X, y, grp_sizes\n",
    "\n",
    "    if HAS_LGB:\n",
    "        Xtr, ytr, gtr = to_group(tr)\n",
    "        Xva, yva, gva = to_group(va)\n",
    "\n",
    "        # ----- core API with callbacks (รองรับหลายเวอร์ชัน) -----\n",
    "        try:\n",
    "            dtr = lgb.Dataset(Xtr, label=ytr, group=gtr)\n",
    "            dva = lgb.Dataset(Xva, label=yva, group=gva, reference=dtr)\n",
    "            params = dict(\n",
    "                objective=\"lambdarank\",\n",
    "                metric=\"ndcg\",          # <--- สำคัญ: ใช้ 'ndcg' + eval_at แทน 'ndcg@k'\n",
    "                eval_at=[3, 5],        # <--- ระบุ k ที่ต้องการประเมิน\n",
    "                learning_rate=0.05,\n",
    "                num_leaves=63,\n",
    "                min_data_in_leaf=100,\n",
    "                feature_fraction=0.8,\n",
    "                bagging_fraction=0.8,\n",
    "                bagging_freq=1,\n",
    "                verbosity=-1,\n",
    "                seed=SEED\n",
    "            )\n",
    "            cbs = []\n",
    "            # ใส่ early_stopping ผ่าน callback (บางเวอร์ชันเท่านั้น)\n",
    "            try:\n",
    "                cbs.append(lgb.early_stopping(stopping_rounds=100))\n",
    "            except Exception:\n",
    "                pass\n",
    "            # ใส่ log interval ถ้ามี\n",
    "            try:\n",
    "                cbs.append(lgb.log_evaluation(100))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                model = lgb.train(\n",
    "                    params,\n",
    "                    dtr,\n",
    "                    num_boost_round=800,\n",
    "                    valid_sets=[dtr, dva],\n",
    "                    valid_names=[\"train\",\"valid\"],\n",
    "                    callbacks=cbs\n",
    "                )\n",
    "            except ValueError:\n",
    "                # ถ้ายัง complain เรื่อง metric/early stopping ให้รันแบบไม่มี early stopping\n",
    "                model = lgb.train(\n",
    "                    params,\n",
    "                    dtr,\n",
    "                    num_boost_round=800,\n",
    "                    valid_sets=[dtr, dva],\n",
    "                    valid_names=[\"train\",\"valid\"]\n",
    "                )\n",
    "            use_core_api = True\n",
    "\n",
    "        except Exception:\n",
    "            # ----- fallback เป็น sklearn API LGBMRanker -----\n",
    "            ranker = lgb.LGBMRanker(\n",
    "                objective=\"lambdarank\",\n",
    "                n_estimators=800,\n",
    "                learning_rate=0.05,\n",
    "                num_leaves=63,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=SEED\n",
    "            )\n",
    "            try:\n",
    "                # บางเวอร์ชันรองรับ eval_at ผ่าน set_params\n",
    "                ranker.set_params(metric=\"ndcg\", eval_at=[3,5])\n",
    "            except Exception:\n",
    "                pass\n",
    "            try:\n",
    "                ranker.fit(\n",
    "                    Xtr, ytr,\n",
    "                    group=gtr.tolist(),\n",
    "                    eval_set=[(Xva, yva)],\n",
    "                    eval_group=[gva.tolist()]\n",
    "                )\n",
    "            except TypeError:\n",
    "                ranker.fit(Xtr, ytr, group=gtr.tolist())\n",
    "            model = ranker\n",
    "            use_core_api = False\n",
    "\n",
    "        # ----- ประเมิน NDCG -----\n",
    "        ndcgs = {f\"ndcg@{k}\":[] for k in k_list}\n",
    "        for eid, grp in va.groupby(\"event_id\"):\n",
    "            if use_core_api:\n",
    "                s = model.predict(grp[F].fillna(0).values,\n",
    "                                  num_iteration=getattr(model, \"best_iteration\", None))\n",
    "            else:\n",
    "                s = model.predict(grp[F].fillna(0).values)\n",
    "            grp = grp.assign(_s=s).sort_values(\"_s\", ascending=False)\n",
    "            for k in k_list:\n",
    "                ndcgs[f\"ndcg@{k}\"].append(ndcg_at_k(grp[\"label\"].values, k))\n",
    "        return {\"model\": model, \"feature_cols\": F, \"report\": {m: float(np.mean(v)) for m,v in ndcgs.items()}}\n",
    "\n",
    "    else:\n",
    "        # Fallback: pointwise classifier\n",
    "        clf = GradientBoostingClassifier(random_state=SEED)\n",
    "        Xtr, ytr, _ = to_group(tr)\n",
    "        Xva, yva, _ = to_group(va)\n",
    "        clf.fit(Xtr, ytr)\n",
    "        ndcgs = {f\"ndcg@{k}\":[] for k in k_list}\n",
    "        for eid, grp in va.groupby(\"event_id\"):\n",
    "            s = clf.predict_proba(grp[F].fillna(0).values)[:,1]\n",
    "            grp = grp.assign(_s=s).sort_values(\"_s\", ascending=False)\n",
    "            for k in k_list:\n",
    "                ndcgs[f\"ndcg@{k}\"].append(ndcg_at_k(grp[\"label\"].values, k))\n",
    "        return {\"model\": clf, \"feature_cols\": F, \"report\": {m: float(np.mean(v)) for m,v in ndcgs.items()}, \"fallback_pointwise\": True}\n",
    "\n",
    "\n",
    "\n",
    "rank_art = train_ranker(rank_df)\n",
    "rank_art[\"report\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cac66307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>promo_id</th>\n",
       "      <th>promo_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>discount</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>product_scope</th>\n",
       "      <th>is_online</th>\n",
       "      <th>est_margin</th>\n",
       "      <th>scope_relevance</th>\n",
       "      <th>...</th>\n",
       "      <th>order_hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>need_state_cluster</th>\n",
       "      <th>is_active_now</th>\n",
       "      <th>days_to_end</th>\n",
       "      <th>discount_norm</th>\n",
       "      <th>type_dup_penalty</th>\n",
       "      <th>dup_product_penalty</th>\n",
       "      <th>ranker_score</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__NOPROMO__</td>\n",
       "      <td>NoPromo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.619114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PR0073</td>\n",
       "      <td>Buy 1 get 1</td>\n",
       "      <td>P0297</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2025-07-18 14:12:00</td>\n",
       "      <td>2025-09-14 14:12:00</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04971</td>\n",
       "      <td>0.078644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PR0078</td>\n",
       "      <td>Buy 1 get 1</td>\n",
       "      <td>P0980</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2025-08-08 09:16:00</td>\n",
       "      <td>2025-09-18 09:16:00</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04971</td>\n",
       "      <td>0.078644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PR0083</td>\n",
       "      <td>Buy 1 get 1</td>\n",
       "      <td>P0587</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2025-09-06 17:03:00</td>\n",
       "      <td>2025-09-19 17:03:00</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04971</td>\n",
       "      <td>0.078644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PR0084</td>\n",
       "      <td>Buy 1 get 1</td>\n",
       "      <td>P0656</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2025-08-01 09:18:00</td>\n",
       "      <td>2025-09-10 09:18:00</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04971</td>\n",
       "      <td>0.078644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PR0095</td>\n",
       "      <td>Buy 1 get 1</td>\n",
       "      <td>P0964</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2025-07-25 20:15:00</td>\n",
       "      <td>2025-09-09 20:15:00</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04971</td>\n",
       "      <td>0.078644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PR0088</td>\n",
       "      <td>Product_Coupon</td>\n",
       "      <td>P0623</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2025-09-04 09:56:00</td>\n",
       "      <td>2025-09-13 09:56:00</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.189538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PR0069</td>\n",
       "      <td>Product_Coupon</td>\n",
       "      <td>P0925</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2025-09-07 08:34:00</td>\n",
       "      <td>2025-09-20 08:34:00</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.194538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PR0067</td>\n",
       "      <td>Product_Coupon</td>\n",
       "      <td>P0182</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2025-08-11 02:29:00</td>\n",
       "      <td>2025-09-21 02:29:00</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.208538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PR0003</td>\n",
       "      <td>Product_Coupon</td>\n",
       "      <td>P0441</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2025-08-04 01:41:00</td>\n",
       "      <td>2025-09-11 01:41:00</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.212538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      promo_id      promo_type product_id  discount          start_date  \\\n",
       "0  __NOPROMO__         NoPromo        NaN       NaN                 NaT   \n",
       "1       PR0073     Buy 1 get 1      P0297     100.0 2025-07-18 14:12:00   \n",
       "2       PR0078     Buy 1 get 1      P0980     100.0 2025-08-08 09:16:00   \n",
       "3       PR0083     Buy 1 get 1      P0587     100.0 2025-09-06 17:03:00   \n",
       "4       PR0084     Buy 1 get 1      P0656     100.0 2025-08-01 09:18:00   \n",
       "5       PR0095     Buy 1 get 1      P0964     100.0 2025-07-25 20:15:00   \n",
       "6       PR0088  Product_Coupon      P0623      48.0 2025-09-04 09:56:00   \n",
       "7       PR0069  Product_Coupon      P0925      43.0 2025-09-07 08:34:00   \n",
       "8       PR0067  Product_Coupon      P0182      29.0 2025-08-11 02:29:00   \n",
       "9       PR0003  Product_Coupon      P0441      25.0 2025-08-04 01:41:00   \n",
       "\n",
       "             end_date product_scope  is_online  est_margin  scope_relevance  \\\n",
       "0                 NaT                        0         0.0              0.0   \n",
       "1 2025-09-14 14:12:00                        0         0.0              0.7   \n",
       "2 2025-09-18 09:16:00                        0         0.0              0.7   \n",
       "3 2025-09-19 17:03:00                        0         0.0              0.7   \n",
       "4 2025-09-10 09:18:00                        0         0.0              0.7   \n",
       "5 2025-09-09 20:15:00                        0         0.0              0.7   \n",
       "6 2025-09-13 09:56:00                        0         0.0              0.7   \n",
       "7 2025-09-20 08:34:00                        0         0.0              0.7   \n",
       "8 2025-09-21 02:29:00                        0         0.0              0.7   \n",
       "9 2025-09-11 01:41:00                        0         0.0              0.7   \n",
       "\n",
       "   ...  order_hour  dayofweek  need_state_cluster  is_active_now  days_to_end  \\\n",
       "0  ...          17          1                   1              0          0.0   \n",
       "1  ...          17          1                   1              1          4.0   \n",
       "2  ...          17          1                   1              1          8.0   \n",
       "3  ...          17          1                   1              1          9.0   \n",
       "4  ...          17          1                   1              1          0.0   \n",
       "5  ...          17          1                   1              1          0.0   \n",
       "6  ...          17          1                   1              1          3.0   \n",
       "7  ...          17          1                   1              1         10.0   \n",
       "8  ...          17          1                   1              1         11.0   \n",
       "9  ...          17          1                   1              1          1.0   \n",
       "\n",
       "   discount_norm  type_dup_penalty  dup_product_penalty  ranker_score  \\\n",
       "0           0.00                 0                  0.0       1.00000   \n",
       "1           1.00                 4                  0.0       0.04971   \n",
       "2           1.00                 4                  0.0       0.04971   \n",
       "3           1.00                 4                  0.0       0.04971   \n",
       "4           1.00                 4                  0.0       0.04971   \n",
       "5           1.00                 4                  0.0       0.04971   \n",
       "6           0.48                 8                  0.0       0.00000   \n",
       "7           0.43                 8                  0.0       0.00000   \n",
       "8           0.29                 8                  0.0       0.00000   \n",
       "9           0.25                 8                  0.0       0.00000   \n",
       "\n",
       "   final_score  \n",
       "0     0.619114  \n",
       "1     0.078644  \n",
       "2     0.078644  \n",
       "3     0.078644  \n",
       "4     0.078644  \n",
       "5     0.078644  \n",
       "6    -0.189538  \n",
       "7    -0.194538  \n",
       "8    -0.208538  \n",
       "9    -0.212538  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_event(event_tx_id, basket_feats, ptype_model, ptype_classes, ptype_featcols,\n",
    "                promos_df, rank_art, topk=TOPK_TYPES, rel_th=REL_TH):\n",
    "    # 0) ดึงแถวบริบท\n",
    "    row = basket_feats[basket_feats[COL_TX]==event_tx_id]\n",
    "    if row.empty:\n",
    "        raise ValueError(\"transaction_id ไม่พบใน basket_feats\")\n",
    "    row = row.iloc[0]\n",
    "\n",
    "    # 1) prior P(type|X)\n",
    "    X = encode_features_for_ptype(row, FEATURE_COLS, ptype_featcols)\n",
    "    probs = ptype_model.predict_proba(X)[0]\n",
    "    class_to_idx = {c:i for i,c in enumerate(ptype_classes)}\n",
    "\n",
    "    # 2) recall (แบบ relaxed)\n",
    "    cands = recall_candidates_for_event_relaxed(\n",
    "        basket_row=row,\n",
    "        promos_df=promos_df,\n",
    "        probs=probs,\n",
    "        classes=ptype_classes,\n",
    "        topk_types=TOPK_TYPES,\n",
    "        relevance_thresh=rel_th,\n",
    "        nopromo_label=\"NoPromo\"\n",
    "    )\n",
    "\n",
    "    # 3) เตรียมฟีเจอร์ให้ครบสำหรับ ranker (เติม \"ก่อน\" ใช้ F)\n",
    "    tmp = cands.copy()\n",
    "\n",
    "    # prior prob ต่อโปรชนิดนั้น\n",
    "    tmp[\"ptype_prob\"] = tmp[\"promo_type\"].apply(\n",
    "        lambda t: probs[class_to_idx.get(t, class_to_idx.get(\"NoPromo\", 0))]\n",
    "    )\n",
    "\n",
    "    # บริบทเหตุการณ์\n",
    "    tmp[\"is_online\"] = int(row.get(COL_ONLINE, 0))\n",
    "    tmp[\"order_hour\"] = int(row.get(COL_ORDER_H, 0))\n",
    "    tmp[\"dayofweek\"] = int(row.get(COL_DOW, 0))\n",
    "    tmp[\"need_state_cluster\"] = int(row.get(\"need_state_cluster\", 0))\n",
    "\n",
    "    # วันที่/ช่วงโปร\n",
    "    now = row.get(\"event_time\", pd.NaT)\n",
    "    if \"start_date\" in tmp.columns and \"end_date\" in tmp.columns and pd.notna(now):\n",
    "        tmp[\"is_active_now\"] = ((tmp[\"start_date\"] <= now) & (now <= tmp[\"end_date\"])).astype(int)\n",
    "        tmp[\"days_to_end\"] = (tmp[\"end_date\"] - now).dt.days.clip(lower=-365, upper=365)\n",
    "    else:\n",
    "        tmp[\"is_active_now\"] = 1\n",
    "        tmp[\"days_to_end\"] = 0\n",
    "\n",
    "    # ส่วนลด normalize\n",
    "    if \"discount\" in tmp.columns:\n",
    "        tmp[\"discount_norm\"] = pd.to_numeric(tmp[\"discount\"], errors=\"coerce\").fillna(0) / 100.0\n",
    "    else:\n",
    "        tmp[\"discount_norm\"] = 0.0\n",
    "\n",
    "    # penalties ในกลุ่มเดียวกัน\n",
    "    tmp[\"type_dup_penalty\"] = (\n",
    "        tmp.groupby(\"promo_type\")[\"promo_id\"].transform(\"count\") - 1\n",
    "    ).clip(lower=0).fillna(0)\n",
    "\n",
    "    if \"product_id\" in tmp.columns:\n",
    "        tmp[\"dup_product_penalty\"] = (\n",
    "            tmp.groupby(\"product_id\")[\"promo_id\"].transform(\"count\") - 1\n",
    "        ).clip(lower=0).fillna(0)\n",
    "    else:\n",
    "        tmp[\"dup_product_penalty\"] = 0.0\n",
    "\n",
    "    # กัน missing ที่ ranker ต้องใช้\n",
    "    needed = [\"ptype_prob\",\"scope_relevance\",\"est_margin\",\n",
    "              \"discount_norm\",\"is_active_now\",\"days_to_end\",\n",
    "              \"type_dup_penalty\",\"dup_product_penalty\",\n",
    "              \"is_online\",\"order_hour\",\"dayofweek\",\"need_state_cluster\"]\n",
    "    for c in needed:\n",
    "        if c not in tmp.columns:\n",
    "            tmp[c] = 0.0\n",
    "    tmp[needed] = tmp[needed].fillna(0)\n",
    "\n",
    "    # 4) จัดอันดับด้วย ranker\n",
    "    F = rank_art[\"feature_cols\"]  # ต้องตรงกับตอนเทรน\n",
    "    mdl = rank_art[\"model\"]\n",
    "    Xr = tmp[F].fillna(0).values\n",
    "\n",
    "    if HAS_LGB and \"fallback_pointwise\" not in rank_art:\n",
    "        s = mdl.predict(Xr, num_iteration=getattr(mdl, \"best_iteration\", None))\n",
    "    else:\n",
    "        s = mdl.predict_proba(Xr)[:, 1]\n",
    "\n",
    "    # normalize และ tie-breaker\n",
    "    s_ptp = float(np.ptp(s))\n",
    "    tmp[\"ranker_score\"] = (s - float(np.min(s))) / s_ptp if s_ptp > 1e-9 else s\n",
    "    if tmp[\"ranker_score\"].nunique() == 1:\n",
    "        tb = (tmp[\"promo_id\"].astype(str).apply(lambda x: (hash(x) % 997) / 997.0)) * 0.01\n",
    "        tmp[\"ranker_score\"] = tmp[\"ranker_score\"] + tb\n",
    "\n",
    "    # 5) blend คะแนนสุดท้าย (หลังมีทุกฟีเจอร์แล้ว)\n",
    "    w = {\n",
    "        \"ptype_prob\": 0.30,\n",
    "        \"ranker_score\": 0.35,\n",
    "        \"scope_relevance\": 0.15,\n",
    "        \"est_margin\": 0.05,\n",
    "        \"discount_norm\": 0.10,\n",
    "        \"is_active_now\": 0.05\n",
    "    }\n",
    "    pen = {\"type_dup_penalty\": 0.05, \"dup_product_penalty\": 0.08}\n",
    "\n",
    "    tmp[\"final_score\"] = (\n",
    "        w[\"ptype_prob\"]*tmp[\"ptype_prob\"] +\n",
    "        w[\"ranker_score\"]*tmp[\"ranker_score\"] +\n",
    "        w[\"scope_relevance\"]*tmp[\"scope_relevance\"] +\n",
    "        w[\"est_margin\"]*tmp[\"est_margin\"] +\n",
    "        w[\"discount_norm\"]*tmp[\"discount_norm\"] +\n",
    "        w[\"is_active_now\"]*tmp[\"is_active_now\"]\n",
    "        - pen[\"type_dup_penalty\"]*tmp[\"type_dup_penalty\"]\n",
    "        - pen[\"dup_product_penalty\"]*tmp[\"dup_product_penalty\"]\n",
    "    )\n",
    "\n",
    "    return tmp.sort_values(\"final_score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "sample_tx_id = basket_feat[COL_TX].iloc[9000]\n",
    "score_event(sample_tx_id, basket_feat, ptype_model, ptype_classes, ptype_featcols, promos_df, rank_art).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "23d521cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>promo_id</th>\n",
       "      <th>promo_type</th>\n",
       "      <th>discount</th>\n",
       "      <th>product_scope</th>\n",
       "      <th>ranker_score</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PR0073</td>\n",
       "      <td>Buy 1 get 1</td>\n",
       "      <td>100.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.57864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PR0078</td>\n",
       "      <td>Buy 1 get 1</td>\n",
       "      <td>100.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.57864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PR0083</td>\n",
       "      <td>Buy 1 get 1</td>\n",
       "      <td>100.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.57864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PR0084</td>\n",
       "      <td>Buy 1 get 1</td>\n",
       "      <td>100.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.57864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PR0095</td>\n",
       "      <td>Buy 1 get 1</td>\n",
       "      <td>100.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.57864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  promo_id   promo_type  discount product_scope  ranker_score  final_score\n",
       "0   PR0073  Buy 1 get 1     100.0                         1.0      0.57864\n",
       "1   PR0078  Buy 1 get 1     100.0                         1.0      0.57864\n",
       "2   PR0083  Buy 1 get 1     100.0                         1.0      0.57864\n",
       "3   PR0084  Buy 1 get 1     100.0                         1.0      0.57864\n",
       "4   PR0095  Buy 1 get 1     100.0                         1.0      0.57864"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tx_id = basket_feat[\"transaction_id\"].iloc[5]\n",
    "rec = score_event(sample_tx_id, basket_feat, ptype_model, ptype_classes, ptype_featcols,\n",
    "                  promos_df, rank_art, topk=2, rel_th=0.30)\n",
    "rec[['promo_id','promo_type','discount','product_scope','ranker_score','final_score']].head(5)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f6e678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
